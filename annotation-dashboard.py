# annotation-dashboard.py
import streamlit as st
import pandas as pd
import plotly.express as px
import numpy as np
from datetime import date

st.set_page_config(page_title="Project Dashboard", layout="wide")

# HEADER
st.markdown("""
<style>
.main-header {
    background: #0176d3;
    padding: 1rem;
    border-radius: 0.5rem;
    color: white;
    text-align: center;
    margin-bottom: 1rem;
}
.metric-card {
    background: #f8f9fa;
    padding: 1rem;
    border-radius: 0.5rem;
    text-align: center;
    margin: 0.5rem;
}
</style>
""", unsafe_allow_html=True)
st.markdown('<div class="main-header"><h1>Project Dashboard</h1></div>', unsafe_allow_html=True)

# SIDEBAR
st.sidebar.header("ğŸ“ ë°ì´í„° ë° íŒŒë¼ë¯¸í„°")
uploaded = st.sidebar.file_uploader("export.csv ì—…ë¡œë“œ", type="csv")
if not uploaded:
    st.info("export.csv íŒŒì¼ì„ ì—…ë¡œë“œí•˜ì„¸ìš”.")
    st.stop()
raw = pd.read_csv(uploaded, dtype=str)

st.sidebar.header("âš™ï¸ í”„ë¡œì íŠ¸ ì„¤ì •")
total_data_qty  = st.sidebar.number_input("ë°ì´í„° ì´ ìˆ˜ëŸ‰", value=1000, min_value=1)
open_date       = st.sidebar.date_input("ì˜¤í”ˆì¼", value=date.today())
target_end_date = st.sidebar.date_input("ëª©í‘œ ì¢…ë£Œì¼", value=date.today())
daily_target    = st.sidebar.number_input("1ì¼ ì²˜ë¦¬ ëª©í‘œ ê±´ìˆ˜", value=20, min_value=1)
unit_price      = st.sidebar.number_input("ì‘ì—… ê±´ë‹¹ ë‹¨ê°€(ì›)", value=100, min_value=0)
review_price    = st.sidebar.number_input("ê²€ìˆ˜ ê±´ë‹¹ ë‹¨ê°€(ì›)", value=50, min_value=0)

# DATA CLEANING
df = raw.rename(columns={
    "í”„ë¡œì íŠ¸ID":"project_id","ë°ì´í„° ID":"data_id","ì‘ì—… ìƒíƒœ":"status",
    "ì‘ì—…ë¶ˆê°€ì—¬ë¶€":"blocked","ìµœì¢… ì˜¤ë¸Œì íŠ¸ ìˆ˜":"annotations_completed",
    "ìˆ˜ì • ì—¬ë¶€":"rework_required","ìœ íš¨ ì˜¤ë¸Œì íŠ¸ ìˆ˜":"valid_count",
    "Worker ID":"worker_id","ì‘ì—…ì ë‹‰ë„¤ì„":"worker_name","Checker ID":"checker_id",
    "ê²€ìˆ˜ì ë‹‰ë„¤ì„":"checker_name","ì‘ì—… ì¢…ë£Œì¼":"work_date","ê²€ìˆ˜ ì¢…ë£Œì¼":"review_date",
    "ì‘ì—… ìˆ˜ì • ì‹œê°„":"work_time_minutes"
})[[
    "data_id","status","annotations_completed","valid_count","rework_required",
    "worker_id","worker_name","checker_id","checker_name",
    "work_date","review_date","work_time_minutes"
]].copy()

df["work_date"]   = pd.to_datetime(df["work_date"], errors="coerce")
df["review_date"]= pd.to_datetime(df["review_date"], errors="coerce")
for c in ["annotations_completed","valid_count","rework_required","work_time_minutes"]:
    df[c] = pd.to_numeric(df[c], errors="coerce").fillna(0).astype(int)

df = df[(df["work_date"].dt.date>=open_date)&(df["work_date"].dt.date<=target_end_date)]
active_days = (target_end_date - open_date).days + 1

# PROJECT OVERVIEW
completed_qty   = df["data_id"].nunique()
remaining_qty   = total_data_qty - completed_qty
progress_pct    = completed_qty/total_data_qty if total_data_qty>0 else 0
remaining_days  = (target_end_date - date.today()).days
elapsed_days    = (date.today() - open_date).days + 1
daily_avg       = completed_qty/elapsed_days if elapsed_days>0 else 0
predicted_total = daily_avg*active_days
predicted_pct   = predicted_total/total_data_qty if total_data_qty>0 else 0

st.markdown("## ğŸ“Š ì „ì²´ í”„ë¡œì íŠ¸ í˜„í™©")
mc1,mc2,mc3,mc4 = st.columns(4)
mc1.markdown(f'<div class="metric-card"><h4>ë°ì´í„° ì´ ìˆ˜ëŸ‰</h4><p>{total_data_qty}</p></div>', unsafe_allow_html=True)
mc2.markdown(f'<div class="metric-card"><h4>ì™„ë£Œ ìˆ˜ëŸ‰</h4><p>{completed_qty}</p></div>', unsafe_allow_html=True)
mc3.markdown(f'<div class="metric-card"><h4>ì”ì—¬ ìˆ˜ëŸ‰</h4><p>{remaining_qty}</p></div>', unsafe_allow_html=True)
mc4.markdown(f'<div class="metric-card"><h4>ì§„í–‰ë¥ </h4><p>{progress_pct:.1%}</p></div>', unsafe_allow_html=True)
mc5,mc6,mc7,mc8 = st.columns(4)
mc5.markdown(f'<div class="metric-card"><h4>ì”ì—¬ì¼</h4><p>{remaining_days}</p></div>', unsafe_allow_html=True)
mc6.markdown(f'<div class="metric-card"><h4>1ì¼ ì²˜ë¦¬ ëª©í‘œ</h4><p>{daily_target}</p></div>', unsafe_allow_html=True)
mc7.markdown(f'<div class="metric-card"><h4>1ì¼ ì²˜ë¦¬ í‰ê· </h4><p>{daily_avg:.1f}</p></div>', unsafe_allow_html=True)
mc8.markdown(f'<div class="metric-card"><h4>ì˜ˆìƒ ì™„ë£Œìœ¨</h4><p>{predicted_pct:.1%}</p></div>', unsafe_allow_html=True)

# PROGRESSION CHART
dates = pd.date_range(open_date,target_end_date)
daily_done = df.groupby(df["work_date"].dt.date)["data_id"].nunique().reindex(dates.date,fill_value=0).cumsum().reset_index()
daily_done.columns=["date","cumulative"]
target_line=pd.DataFrame({"date":dates.date,"cumulative":np.linspace(0,total_data_qty,len(dates))})
fig_proj=px.line(daily_done,x="date",y="cumulative",title="í”„ë¡œì íŠ¸ ì§„í–‰ ì¶”ì´")
fig_proj.add_scatter(x=target_line["date"],y=target_line["cumulative"],mode="lines",name="ëª©í‘œ ì§„í–‰ì„ ")
st.plotly_chart(fig_proj,use_container_width=True)

# WEEKLY PROGRESS - separate
df["month"]=df["work_date"].dt.month
df["wom"]=((df["work_date"].dt.day-1)//7)+1
df["week_label"]=df["month"].astype(str)+"ì›” "+df["wom"].astype(str)+"ì£¼ì°¨"
weekly=df.groupby("week_label").agg(
    work_actual=("annotations_completed","sum"),
    review_actual=("valid_count","sum")
).reset_index()
weekly["work_target"]=daily_target*7
weekly["review_target"]=daily_target*7*0.8
weekly["work_pct"]=weekly["work_actual"]/weekly["work_target"]
weekly["review_pct"]=weekly["review_actual"]/weekly["review_target"]
weekly["review_wait"]=df[(df["annotations_completed"]>0)&df["review_date"].isna()]\
    .groupby("week_label")["data_id"].count().reindex(weekly["week_label"],fill_value=0).values

st.markdown("## ğŸ“Š ì£¼ë³„ ì§„ì²™ë¥ ")
fig_w1=px.bar(weekly,x="week_label",y=["work_actual","work_target"],barmode="group",title="ì£¼ë³„ ì‘ì—…: ì‹¤ì œ vs ëª©í‘œ")
fig_w1.update_xaxes(tickangle=-45)
st.plotly_chart(fig_w1,use_container_width=True)
fig_w2=px.bar(weekly,x="week_label",y=["review_actual","review_target"],barmode="group",title="ì£¼ë³„ ê²€ìˆ˜: ì‹¤ì œ vs ëª©í‘œ")
fig_w2.update_xaxes(tickangle=-45)
st.plotly_chart(fig_w2,use_container_width=True)
st.table(weekly.assign(
    work_pct=weekly["work_pct"].map("{:.1%}".format),
    review_pct=weekly["review_pct"].map("{:.1%}".format)
)[[
    "week_label","work_actual","work_target","work_pct",
    "review_actual","review_target","review_pct","review_wait"
]].rename(columns={
    "week_label":"ì£¼ì°¨","work_actual":"ì‘ì—…ì‹¤ì œ","work_target":"ì‘ì—…ëª©í‘œ","work_pct":"ì‘ì—…ë‹¬ì„±",
    "review_actual":"ê²€ìˆ˜ì‹¤ì œ","review_target":"ê²€ìˆ˜ëª©í‘œ","review_pct":"ê²€ìˆ˜ë‹¬ì„±","review_wait":"ê²€ìˆ˜ëŒ€ê¸°"
}))

# WORKER METRICS & DISPLAY
wd=df.groupby(["worker_id","worker_name"]).agg(
    completed=("annotations_completed","sum"),
    rework=("rework_required","sum"),
    work_time=("work_time_minutes","sum"),
    last_date=("work_date","max")
).reset_index()
wd["hours"]=wd["work_time"]/60
wd["avg_per_task"]=wd["hours"]/wd["completed"].replace(0,np.nan)
wd["daily_time"]=wd["hours"]/active_days
wd["hourly_rate"]=(wd["completed"]/wd["hours"].replace(0,np.nan))*unit_price
wd["reject_rate"]= (wd["rework"]/wd["completed"].replace(0,np.nan)).clip(lower=0)
wd["activity_rate"]=wd["hours"]/(active_days*8)
wd["reject_rate_pct"]=wd["reject_rate"].map("{:.1%}".format)
wd["activity_rate_pct"]=wd["activity_rate"].map("{:.1%}".format)
wd["abnormal"]=((wd["reject_rate"]>=0.3)|(wd["activity_rate"]<=0.5))

st.markdown("## ğŸ‘¥ ì‘ì—…ì í˜„í™©")
summary_w=pd.DataFrame({
    "êµ¬ë¶„":["ì „ì²´ í‰ê· ","í™œì„± í‰ê· "],
    "í™œì„±ë¥ (%)":[wd["activity_rate"].mean(),wd[~wd["abnormal"]]["activity_rate"].mean()],
    "ì‹œê¸‰(ì›)":[wd["hourly_rate"].mean(),wd[~wd["abnormal"]]["hourly_rate"].mean()],
    "ë°˜ë ¤ìœ¨(%)":[wd["reject_rate"].mean(),wd[~wd["abnormal"]]["reject_rate"].mean()],
    "ì‘ì—…ìˆ˜ëŸ‰":[wd["completed"].mean(),wd[~wd["abnormal"]]["completed"].mean()]
})
summary_w[["í™œì„±ë¥ (%)","ë°˜ë ¤ìœ¨(%)"]]=summary_w[["í™œì„±ë¥ (%)","ë°˜ë ¤ìœ¨(%)"]].applymap(lambda x:f"{x:.1%}")
summary_w["ì‘ì—…ìˆ˜ëŸ‰"]=summary_w["ì‘ì—…ìˆ˜ëŸ‰"].map(lambda x:f"{x:.1f}")
st.table(summary_w)

fig_wd=px.bar(wd.sort_values("completed",ascending=False),x="worker_name",y="completed",title="ì‘ì—…ëŸ‰ by ì‘ì—…ì")
st.plotly_chart(fig_wd,use_container_width=True)
st.dataframe(wd.sort_values("completed",ascending=False)[[
    "worker_id","worker_name","activity_rate_pct","hourly_rate","reject_rate_pct","completed",
    "hours","avg_per_task","daily_time","last_date","abnormal"
]].rename(columns={
    "worker_id":"ID","worker_name":"ë‹‰ë„¤ì„","activity_rate_pct":"í™œì„±ë¥ (%)","hourly_rate":"ì‹œê¸‰(ì›)",
    "reject_rate_pct":"ë°˜ë ¤ìœ¨(%)","completed":"ì‘ì—…ìˆ˜ëŸ‰","hours":"ì°¸ì—¬ì‹œê°„(ì‹œê°„)",
    "avg_per_task":"ê±´ë‹¹í‰ê· (ì‹œê°„)","daily_time":"ì¼í‰ê· (ì‹œê°„)","last_date":"ë§ˆì§€ë§‰ì‘ì—…ì¼","abnormal":"ì´ìƒì°¸ì—¬ì"
}),use_container_width=True)

# CHECKER METRICS & DISPLAY
cd=df.groupby(["checker_id","checker_name"]).agg(
    reviews=("data_id","count"),
    valid=("valid_count","sum"),
    last_date=("review_date","max")
).reset_index()
cd["hours"]=cd["reviews"]
cd["avg_per_task"]=cd["hours"]/cd["reviews"].replace(0,np.nan)
cd["daily_time"]=cd["hours"]/active_days
cd["hourly_rate"]=(cd["reviews"]/cd["hours"].replace(0,np.nan))*review_price
cd["error_rate"]=((cd["reviews"]-cd["valid"])/cd["reviews"].replace(0,np.nan)).clip(lower=0)
cd["activity_rate"]=cd["hours"]/(active_days*8)
cd["error_rate_pct"]=cd["error_rate"].map("{:.1%}".format)
cd["activity_rate_pct"]=cd["activity_rate"].map("{:.1%}".format)
cd["abnormal"]=((cd["error_rate"]>=0.3)|(cd["activity_rate"]<=0.5))

st.markdown("## ğŸ‘¥ ê²€ìˆ˜ì í˜„í™©")
summary_c=pd.DataFrame({
    "êµ¬ë¶„":["ì „ì²´ í‰ê· ","í™œì„± í‰ê· "],
    "í™œì„±ë¥ (%)":[cd["activity_rate"].mean(),cd[~cd["abnormal"]]["activity_rate"].mean()],
    "ì‹œê¸‰(ì›)":[cd["hourly_rate"].mean(),cd[~cd["abnormal"]]["hourly_rate"].mean()],
    "ì˜¤ë¥˜ìœ¨(%)":[cd["error_rate"].mean(),cd[~cd["abnormal"]]["error_rate"].mean()],
    "ê²€ìˆ˜ìˆ˜ëŸ‰":[cd["reviews"].mean(),cd[~cd["abnormal"]]["reviews"].mean()]
})
summary_c[["í™œì„±ë¥ (%)","ì˜¤ë¥˜ìœ¨(%)"]]=summary_c[["í™œì„±ë¥ (%)","ì˜¤ë¥˜ìœ¨(%)"]].applymap(lambda x:f"{x:.1%}")
summary_c["ê²€ìˆ˜ìˆ˜ëŸ‰"]=summary_c["ê²€ìˆ˜ìˆ˜ëŸ‰"].map(lambda x:f"{x:.1f}")
st.table(summary_c)

fig_cd=px.bar(cd.sort_values("reviews",ascending=False),x="checker_name",y="reviews",title="ê²€ìˆ˜ëŸ‰ by ê²€ìˆ˜ì")
st.plotly_chart(fig_cd,use_container_width=True)
st.dataframe(cd.sort_values("reviews",ascending=False)[[
    "checker_id","checker_name","activity_rate_pct","hourly_rate","error_rate_pct","reviews",
    "hours","avg_per_task","daily_time","last_date","abnormal"
]].rename(columns={
    "checker_id":"ID","checker_name":"ë‹‰ë„¤ì„","activity_rate_pct":"í™œì„±ë¥ (%)","hourly_rate":"ì‹œê¸‰(ì›)",
    "error_rate_pct":"ì˜¤ë¥˜ìœ¨(%)","reviews":"ê²€ìˆ˜ìˆ˜ëŸ‰","hours":"ì°¸ì—¬ì‹œê°„(ì‹œê°„)",
    "avg_per_task":"ê±´ë‹¹í‰ê· (ì‹œê°„)","daily_time":"ì¼í‰ê· (ì‹œê°„)","last_date":"ë§ˆì§€ë§‰ê²€ìˆ˜ì¼","abnormal":"ì´ìƒì°¸ì—¬ì"
}),use_container_width=True)
